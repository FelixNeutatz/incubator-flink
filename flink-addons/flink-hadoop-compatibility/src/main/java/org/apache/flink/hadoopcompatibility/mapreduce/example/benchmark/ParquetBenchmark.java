/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package org.apache.flink.hadoopcompatibility.mapreduce.example.benchmark;


import org.apache.flink.api.common.functions.FilterFunction;
import org.apache.flink.api.common.functions.JoinFunction;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.aggregation.Aggregations;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.api.java.tuple.Tuple4;
import org.apache.flink.hadoopcompatibility.mapreduce.HadoopInputFormat;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.filter.CustomerFilter;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.filter.LineitemFilter;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.filter.OrderFilter;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.thrift.CustomerTable;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.thrift.LineitemTable;
import org.apache.flink.hadoopcompatibility.mapreduce.example.tpch.thrift.OrderTable;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.Job;
import parquet.hadoop.ParquetInputFormat;
import parquet.hadoop.thrift.ParquetThriftInputFormat;
import parquet.hadoop.thrift.ThriftReadSupport;

import java.io.IOException;
import java.text.DateFormat;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;

/**
 * This program implements a modified version of the TPC-H query 3. The
 * example demonstrates how to assign names to fields by extending the Tuple class.
 * The original query can be found at
 * <a href="http://www.tpc.org/tpch/spec/tpch2.16.0.pdf">http://www.tpc.org/tpch/spec/tpch2.16.0.pdf</a> (page 29).
 *
 * <p>
 * This program implements the following SQL equivalent:
 *
 * <p>
 * <code><pre>
 * SELECT 
 *      l_orderkey, 
 *      SUM(l_extendedprice*(1-l_discount)) AS revenue,
 *      o_orderdate, 
 *      o_shippriority 
 * FROM customer, 
 *      orders, 
 *      lineitem 
 * WHERE
 *      c_mktsegment = '[SEGMENT]' 
 *      AND c_custkey = o_custkey
 *      AND l_orderkey = o_orderkey
 *      AND o_orderdate < date '[DATE]'
 *      AND l_shipdate > date '[DATE]'
 * GROUP BY
 *      l_orderkey, 
 *      o_orderdate, 
 *      o_shippriority;
 * </pre></code>
 *
 * <p>
 * Compared to the original TPC-H query this version does not sort the result by revenue
 * and orderdate.
 *
 * <p>
 * Input files are plain text CSV files using the pipe character ('|') as field separator 
 * as generated by the TPC-H data generator which is available at <a href="http://www.tpc.org/tpch/">http://www.tpc.org/tpch/</a>.
 *
 *  <p>
 * Usage: <code>TPCHQuery3 &lt;lineitem-csv path&gt; &lt;customer-csv path&gt; &lt;orders-csv path&gt; &lt;result path&gt;</code><br>
 *  
 * <p>
 * This example shows how to use:
 * <ul>
 * <li> custom data type derived from tuple data types
 * <li> inline-defined functions
 * <li> build-in aggregation functions
 * </ul>
 */
@SuppressWarnings("serial")
public class ParquetBenchmark {

	// *************************************************************************
	//     PROGRAM
	// *************************************************************************
	
	public static void main(String[] args) throws Exception {
		
		if(!parseParameters(args)) {
			return;
		}

		final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();

		// get input data
		DataSet<Lineitem> lineitems = getLineitemDataSet(env).map(new MapLineitems());

		lineitems = lineitems.filter(
				new FilterFunction<Lineitem>() {
					private final DateFormat format = new SimpleDateFormat("yyyy-MM-dd");
					private final Date date = format.parse("1995-03-12");

					@Override
					public boolean filter(Lineitem l) throws ParseException {
						return format.parse(l.getShipdate()).after(date);
					}
				});
		
		lineitems.sum(0).print();
		
		// execute program
		env.execute("TPCH Query 3 Example");
		
	}


	// *************************************************************************
	//     UTIL METHODS
	// *************************************************************************
	
	private static String lineitemPath;
	
	private static boolean parseParameters(String[] programArguments) {
		
		if(programArguments.length > 0) {
			if(programArguments.length == 1) {
				lineitemPath = programArguments[0];
			} else {
				System.err.println("Usage: TPCHQuery3 <lineitem-csv path>");
				return false;
			}
		} else {
			System.err.println("This program expects data from the TPC-H benchmark as input data.\n" +
								"  Due to legal restrictions, we can not ship generated data.\n" +
								"  You can find the TPC-H data generator at http://www.tpc.org/tpch/.\n" + 
								"  Usage: TPCHQuery3 <lineitem-csv path> <customer-csv path> <orders-csv path> <result path>");
			return false;
		}
		return true;
	}






	private static final class MapLineitems implements MapFunction<Tuple2<Void,LineitemTable>,Lineitem> {
		
		@Override
		public Lineitem map(Tuple2<Void,LineitemTable> value) {
			Lineitem tuple = new Lineitem();
			tuple.f0 = value.f1.getORDERKEY();
			tuple.f1 = value.f1.getEXTENDEDPRICE();
			tuple.f2 = value.f1.getDISCOUNT();
			tuple.f3 = value.f1.getSHIPDATE();
			return tuple;

		}
	}

	private static DataSet<Tuple2<Void, LineitemTable>> getLineitemDataSet(ExecutionEnvironment env) throws IOException {

		//env.setDegreeOfParallelism(1);

		Job job = Job.getInstance();

		ParquetInputFormat.setReadSupportClass(job, ThriftReadSupport.class);
		job.getConfiguration().set("parquet.thrift.column.filter", "ORDERKEY;EXTENDEDPRICE;DISCOUNT;SHIPDATE");
		

		HadoopInputFormat hadoopInputFormat = new HadoopInputFormat(new ParquetThriftInputFormat(), Void.class, LineitemTable.class, job);

		// Filter all Lineitems with l_shipdate > 12.03.1995
		//ParquetThriftInputFormat.setUnboundRecordFilter(job, LineitemFilter.class);
		
		
		ParquetThriftInputFormat.addInputPath(job, new Path(lineitemPath));

		DataSet<Tuple2<Void, LineitemTable>> data = env.createInput(hadoopInputFormat);
		
		return data;
	}
	
	
	public static class Lineitem extends Tuple4<Long, Double, Double, String> {

		public Long getOrderkey() { return this.f0; }
		public Double getExtendedprice() { return this.f1; }
		public Double getDiscount() { return this.f2; }
		public String getShipdate() { return this.f3; }
	}

}
